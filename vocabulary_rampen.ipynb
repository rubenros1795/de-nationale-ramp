{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import glob\n",
    "from pattern.nl import parse, split\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:/Rampen/ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrigrams(list_trigrams,sy,ey,interval,decade=False):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(sy,ey,interval):\n",
    "\n",
    "        d = pd.read_csv(str(i) + \"-trigrams.csv\")\n",
    "        d = d[d['gram'].str.contains(\"|\".join(list_trigrams))]\n",
    "        print(len(d))\n",
    "        d['year'] = str(i)\n",
    "        df = df.append(d)\n",
    "    \n",
    "    if decade == True:\n",
    "        df['year'] = df['year'].astype(int) // 10 * 10\n",
    "    \n",
    "    df = df.groupby(['gram','year']).sum().reset_index().pivot(columns='year',index='gram',values='count').reset_index()\n",
    "    df['sum'] = df[df.columns[1:]].sum(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "21\n",
      "36\n",
      "46\n",
      "10\n",
      "17\n",
      "30\n",
      "23\n",
      "25\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "d = GetTrigrams(['rampen_des_',\"rampen_der_\",\"rampen_van_\",\"ramp_der_\",\"ramp_des\",\"ramp_van\"],1840,1850,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = [w for w in list(set(d['gram']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_words = []\n",
    "\n",
    "for word in list_words:\n",
    "    di = dict(sorted(d[['gram','sum']].values.tolist()))\n",
    "    related = dict()\n",
    "    \n",
    "    for word2 in list_words:\n",
    "        \n",
    "        \n",
    "        if editdistance.eval(word,word2) < 3:\n",
    "            count = di[word2]\n",
    "            \n",
    "            related.update({word2:count})\n",
    "    if max(related, key=related.get) == word:\n",
    "        true_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-76-aa925556db34>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-76-aa925556db34>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    sorted(list(set([w.split(\"_\")[2] for w in true_words if \"1\" in w.split(\"_\")[2]]))\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "sorted(list(set([w.split(\"_\")[2] for w in true_words if \"1\" in w.split(\"_\")[2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
